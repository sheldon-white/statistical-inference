{
    "contents" : "---\ntitle       : T Confidence Intervals\nsubtitle    : Statistical Inference\nauthor      : Brian Caffo, Jeff Leek, Roger Peng\njob         : Johns Hopkins Bloomberg School of Public Health\nlogo        : bloomberg_shield.png\nframework   : io2012        # {io2012, html5slides, shower, dzslides, ...}\nhighlighter : highlight.js  # {highlight.js, prettify, highlight}\nhitheme     : tomorrow      # \nurl:\n  lib: ../../librariesNew\n  assets: ../../assets\nwidgets     : [mathjax]            # {mathjax, quiz, bootstrap}\nmode        : selfcontained # {standalone, draft}\n---\n## T Confidence intervals\n\n- In the previous, we discussed creating a confidence interval using the CLT\n  - They took the form $Est \\pm ZQ \\times SE_{Est}$\n- In this lecture, we discuss some methods for small samples, notably Gosset's $t$ distribution and $t$ confidence intervals\n  - They are of the form $Est \\pm TQ \\times SE_{Est}$\n- These are some of the handiest of intervals\n- If you want a rule between whether to use a $t$ interval\nor normal interval, just always use the $t$ interval\n- We'll cover the one and two group versions\n\n---\n\n## Gosset's $t$ distribution\n\n- Invented by William Gosset (under the pseudonym \"Student\") in 1908\n- Has thicker tails than the normal\n- Is indexed by a degrees of freedom; gets more like a standard normal as df gets larger\n- It assumes that the underlying data are iid \nGaussian with the result that\n$$\n\\frac{\\bar X - \\mu}{S/\\sqrt{n}}\n$$\nfollows Gosset's $t$ distribution with $n-1$ degrees of freedom\n- (If we replaced $s$ by $\\sigma$ the statistic would be exactly standard normal)\n- Interval is $\\bar X \\pm t_{n-1} S/\\sqrt{n}$ where $t_{n-1}$\nis the relevant quantile\n\n---\n## Code for manipulate\n```{r, echo=TRUE,eval=FALSE}\nk <- 1000\nxvals <- seq(-5, 5, length = k)\nmyplot <- function(df){\n  d <- data.frame(y = c(dnorm(xvals), dt(xvals, df)),\n                  x = xvals,\n                  dist = factor(rep(c(\"Normal\", \"T\"), c(k,k))))\n  g <- ggplot(d, aes(x = x, y = y)) \n  g <- g + geom_line(size = 2, aes(colour = dist))\n  g\n}\nmanipulate(myplot(mu), mu = slider(1, 20, step = 1))  \n```\n\n---\n## Easier to see\n```{r, eval = FALSE, echo = TRUE}\npvals <- seq(.5, .99, by = .01)\nmyplot2 <- function(df){\n  d <- data.frame(n= qnorm(pvals),t=qt(pvals, df),\n                  p = pvals)\n  g <- ggplot(d, aes(x= n, y = t))\n  g <- g + geom_abline(size = 2, col = \"lightblue\")\n  g <- g + geom_line(size = 2, col = \"black\")\n  g <- g + geom_vline(xintercept = qnorm(0.975))\n  g <- g + geom_hline(yintercept = qt(0.975, df))\n  g\n}\nmanipulate(myplot2(df), df = slider(1, 20, step = 1))\n```\n\n---\n\n## Note's about the $t$ interval\n\n- The $t$ interval technically assumes that the data are iid normal, though it is robust to this assumption\n- It works well whenever the distribution of the data is roughly symmetric and mound shaped\n- Paired observations are often analyzed using the $t$ interval by taking differences\n- For large degrees of freedom, $t$ quantiles become the same as standard normal quantiles; therefore this interval converges to the same interval as the CLT yielded\n- For skewed distributions, the spirit of the $t$ interval assumptions are violated\n  - Also, for skewed distributions, it doesn't make a lot of sense to center the interval at the mean\n  - In this case, consider taking logs or using a different summary like the median\n- For highly discrete data, like binary, other intervals are available\n\n---\n\n## Sleep data\n\nIn R typing `data(sleep)` brings up the sleep data originally\nanalyzed in Gosset's Biometrika paper, which shows the increase in\nhours for 10 patients on two soporific drugs. R treats the data as two\ngroups rather than paired.\n\n---\n## The data\n```{r}\ndata(sleep)\nhead(sleep)\n```\n\n---\n## Plotting the data\n```{r, echo = FALSE, fig.width=6, fig.height=6, fig.align='center'}\nlibrary(ggplot2)\ng <- ggplot(sleep, aes(x = group, y = extra, group = factor(ID)))\ng <- g + geom_line(size = 1, aes(colour = ID)) + geom_point(size =10, pch = 21, fill = \"salmon\", alpha = .5)\ng\n```\n\n---\n## Results\n```{r, echo=TRUE}\ng1 <- sleep$extra[1 : 10]; g2 <- sleep$extra[11 : 20]\ndifference <- g2 - g1\nmn <- mean(difference); s <- sd(difference); n <- 10\n```\n```{r, echo=TRUE,eval=FALSE}\nmn + c(-1, 1) * qt(.975, n-1) * s / sqrt(n)\nt.test(difference)\nt.test(g2, g1, paired = TRUE)\nt.test(extra ~ I(relevel(group, 2)), paired = TRUE, data = sleep)\n```\n\n---\n## The results\n(After a little formatting)\n```{r, echo = FALSE}\nrbind(\nmn + c(-1, 1) * qt(.975, n-1) * s / sqrt(n),\nas.vector(t.test(difference)$conf.int),\nas.vector(t.test(g2, g1, paired = TRUE)$conf.int),\nas.vector(t.test(extra ~ I(relevel(group, 2)), paired = TRUE, data = sleep)$conf.int)\n)\n```\n\n---\n\n## Independent group $t$ confidence intervals\n\n- Suppose that we want to compare the mean blood pressure between two groups in a randomized trial; those who received the treatment to those who received a placebo\n- We cannot use the paired t test because the groups are independent and may have different sample sizes\n- We now present methods for comparing independent groups\n\n---\n## Confidence interval\n\n- Therefore a $(1 - \\alpha)\\times 100\\%$ confidence interval for $\\mu_y - \\mu_x$ is \n$$\n    \\bar Y - \\bar X \\pm t_{n_x + n_y - 2, 1 - \\alpha/2}S_p\\left(\\frac{1}{n_x} + \\frac{1}{n_y}\\right)^{1/2}\n$$\n- The pooled variance estimator is $$S_p^2 = \\{(n_x - 1) S_x^2 + (n_y - 1) S_y^2\\}/(n_x + n_y - 2)$$ \n- Remember this interval is assuming a constant variance across the two groups\n- If there is some doubt, assume a different variance per group, which we will discuss later\n\n---\n\n## Example\n### Based on Rosner, Fundamentals of Biostatistics\n(Really a very good reference book)\n\n- Comparing SBP for 8 oral contraceptive users versus 21 controls\n- $\\bar X_{OC} = 132.86$ mmHg with $s_{OC} = 15.34$ mmHg\n- $\\bar X_{C} = 127.44$ mmHg with $s_{C} = 18.23$ mmHg\n- Pooled variance estimate\n```{r}\nsp <- sqrt((7 * 15.34^2 + 20 * 18.23^2) / (8 + 21 - 2))\n132.86 - 127.44 + c(-1, 1) * qt(.975, 27) * sp * (1 / 8 + 1 / 21)^.5\n```\n\n\n---\n## Mistakenly treating the sleep data as grouped\n```{r}\nn1 <- length(g1); n2 <- length(g2)\nsp <- sqrt( ((n1 - 1) * sd(x1)^2 + (n2-1) * sd(x2)^2) / (n1 + n2-2))\nmd <- mean(g2) - mean(g1)\nsemd <- sp * sqrt(1 / n1 + 1/n2)\nrbind(\nmd + c(-1, 1) * qt(.975, n1 + n2 - 2) * semd,  \nt.test(g2, g1, paired = FALSE, var.equal = TRUE)$conf,\nt.test(g2, g1, paired = TRUE)$conf\n)\n```\n\n---\n## Grouped versus independent\n```{r, echo = FALSE, fig.width=6, fig.height=6, fig.align='center'}\nlibrary(ggplot2)\ng <- ggplot(sleep, aes(x = group, y = extra, group = factor(ID)))\ng <- g + geom_line(size = 1, aes(colour = ID)) + geom_point(size =10, pch = 21, fill = \"salmon\", alpha = .5)\ng\n```\n\n---\n\n## `ChickWeight` data in R\n```{r}\nlibrary(datasets); data(ChickWeight); library(reshape2)\n##define weight gain or loss\nwideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = \"weight\")\nnames(wideCW)[-(1 : 2)] <- paste(\"time\", names(wideCW)[-(1 : 2)], sep = \"\")\nlibrary(dplyr)\nwideCW <- mutate(wideCW,\n  gain = time21 - time0\n)\n\n```\n\n---\n## Plotting the raw data\n\n```{r, echo =FALSE, fig.align='center', fig.width=12, fig.height=6}\ng <- ggplot(ChickWeight, aes(x = Time, y = weight, \n                             colour = Diet, group = Chick))\ng <- g + geom_line()\ng <- g + stat_summary(aes(group = 1), geom = \"line\", fun.y = mean, size = 1, col = \"black\")\ng <- g + facet_grid(. ~ Diet)\ng\n```\n\n\n\n---\n## Weight gain by diet\n```{r, echo=FALSE, fig.align='center', fig.width=6, fig.height=6, warning=FALSE}\ng <- ggplot(wideCW, aes(x = factor(Diet), y = gain, fill = factor(Diet)))\ng <- g + geom_violin(col = \"black\", size = 2)\ng\n\n```\n\n---\n## Let's do a t interval\n```{r}\nwideCW14 <- subset(wideCW, Diet %in% c(1, 4))\nrbind(\nt.test(gain ~ Diet, paired = FALSE, var.equal = TRUE, data = wideCW14)$conf,\nt.test(gain ~ Diet, paired = FALSE, var.equal = FALSE, data = wideCW14)$conf\n)\n```\n\n\n---\n\n## Unequal variances\n\n- Under unequal variances\n$$\n\\bar Y - \\bar X \\pm t_{df} \\times \\left(\\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y}\\right)^{1/2}\n$$\nwhere $t_{df}$ is calculated with degrees of freedom\n$$\ndf=    \\frac{\\left(S_x^2 / n_x + S_y^2/n_y\\right)^2}\n    {\\left(\\frac{S_x^2}{n_x}\\right)^2 / (n_x - 1) +\n      \\left(\\frac{S_y^2}{n_y}\\right)^2 / (n_y - 1)}\n$$\nwill be approximately a 95% interval\n- This works really well\n  - So when in doubt, just assume unequal variances\n\n---\n\n## Example\n\n- Comparing SBP for 8 oral contraceptive users versus 21 controls\n- $\\bar X_{OC} = 132.86$ mmHg with $s_{OC} = 15.34$ mmHg\n- $\\bar X_{C} = 127.44$ mmHg with $s_{C} = 18.23$ mmHg\n- $df=15.04$, $t_{15.04, .975} = 2.13$\n- Interval\n$$\n132.86 - 127.44 \\pm 2.13 \\left(\\frac{15.34^2}{8} + \\frac{18.23^2}{21} \\right)^{1/2}\n= [-8.91, 19.75]\n$$\n- In R, `t.test(..., var.equal = FALSE)`\n\n---\n## Comparing other kinds of data\n* For binomial data, there's lots of ways to compare two groups\n  * Relative risk, risk difference, odds ratio.\n  * Chi-squared tests, normal approximations, exact tests.\n* For count data, there's also Chi-squared tests and exact tests.\n* We'll leave the discussions for comparing groups of data for binary\n  and count data until covering glms in the regression class.\n* In addition, Mathematical Biostatistics Boot Camp 2 covers many special\n  cases relevant to biostatistics.\n\n",
    "created" : 1415761234759.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3211569755",
    "id" : "895F01C4",
    "lastKnownWriteTime" : 1415932941,
    "path" : "~/Dropbox/coursera/statistical-inference/rmd/08_tCIs.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}